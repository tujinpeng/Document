• 应用负载 : 			我们用 A10+Nginx
• 分布式服务框架 :		我们用 Dubbo
• 集中式Cache :		我们用 Memcached + Redis
• 异步消息 :			我们用 activeMQ / kafka
• noSQL :			我们用 mongoDB / ElasticSearch
• 数据库集群+读写分离: 我们用 LvReadOnly / myCat
• 系统监控/日志收集 :	我们用 Zabbix / Logeye / open-falcon / CAT  
• 配置中心 :			我们有 Sweet
• 大数据:				我们已起步
• AI:				暂时没有


1.迁库 服务拆分
2.自由行景酒打包
3.时间价格计算
4.飞猪去哪儿驴妈妈售卖商品api对接
5.

优化：

我们需要整理下,线路这边针对压测做过什么优化的

1. 自主套餐价格服务压测
(1)价格计算任务过多时,对实时性要求比较低的任务,降低优先级(比如佣金和起价)
(2)针对套餐状态, 状态为无效或者不完整的套餐变价不计算.
(3)针对酒店子系统的一天一次价格变更消息,做了合并后计算.
(4)针对接收到的商品长时间段的变价消息进行优化,取套餐打包的多个商品中最小的价格时间段进行计算,避免大量循环计算

2. 批量价格设置
用到两个线程池,变价规则录入的线程池和价格线程池; 对第一个线程池做了线程调节;
第二个线程池其实就是LTS taskTracker的线程池, 这个线程池利用了lts的负载均衡功能,对高峰期做了削峰处理, 
限制机器cpu超过80%或内存使用超过90%时暂缓执行计算任务.

3. 自动打包
(1)自动打包时,会调用主站findProductDetail接口,这个接口内容很多,频繁调用对分销和主站都有影响; 
后面优化的时候, 把大接口拆分成不同的小接口, 提高了打包的吞吐量.
(2)获取不到JDBC线程池问题, 适当调大了每台应用的最大线程数
(3)部分代码的瓶颈在log4j的日志打印, 因为log4j的日志打印有Synchronized锁, 对性能要求比较高的地方,尽量不要打日志.
   日志打印框架建议换成log-back.
(4)我们分销打包的逻辑比较复杂, 不可避免的有很多循环, 复杂逻辑最好在循环外将数据准备好(通过访问数据库,或者调用远程服务),
   循环中避免不必要的循环.



####################线上问题####################：
1.当tnt_dist集群中有一台机器线程池满了后(假死，不处理请求了)，其他正常机器的流量下降，调用方tnt_back整个服务不可用（很慢）

 原因：由于dubbo线程池满的异常信息反馈不了客户端(异常发送也是要经过
 dubbo线程池），导致客户端很多线程一直在超时，然后导致客户端没有线程发起请求，从而导致客户端服务雪崩。

 解决方案：让提供方发送异常信息不走dubbo线程池，走io线程池，修改dubbo消息分发的策略。


 com.lvmama.vst.api.order.service.VstCommOrderQueryService#findOrderDetail这个接口返回的OrderBaseVo.


 182717  834623









